{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "10000\n",
      "10000\n",
      "55000\n",
      "55000\n",
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\".\", one_hot=True)\n",
    "print(len(mnist.test.images))\n",
    "print(len(mnist.test.labels))\n",
    "print(len(mnist.train.images))\n",
    "print(len(mnist.train.labels))\n",
    "print(mnist.train.images.shape) # An array of flatten images\n",
    "print(mnist.train.labels.shape) # An array of one-hot lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Const():\n",
    "    def __init__(self):\n",
    "        self.neurons_1 = 10\n",
    "        self.neurons_2 = 5\n",
    "        self.number_classes= 10\n",
    "        self.input_dimension = 28*28\n",
    "        self.learning_rate = 0.001\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 2**9\n",
    "        self.iterations = int(np.ceil(mnist.train.num_examples / self.batch_size))\n",
    "        \n",
    "const = Const()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape= [None, 28*28])\n",
    "y = tf.placeholder(dtype=tf.float32, shape= [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    * some tools\n",
    "'''\n",
    "class fully_connected_layer():\n",
    "    '''Holds a layer weights and biases'''\n",
    "    def __init__(self, neurons, input_size):\n",
    "        '''shape: neurons x input_size'''\n",
    "        self.weights = tf.Variable(tf.random_normal([input_size, neurons]))\n",
    "        self.biases  = tf.Variable(tf.random_normal([neurons]))\n",
    "\n",
    "def activation(vector):\n",
    "    return tf.nn.relu(vector)\n",
    "\n",
    "'''\n",
    "    * Fully Connected Network\n",
    "'''\n",
    "def feed_forward_neural_network(X):\n",
    "    '''Defining the grpah\n",
    "        * layer_m: holds the weights and biases of layer m\n",
    "    '''\n",
    "    layer_1      = fully_connected_layer(input_size=const.input_dimension, neurons=const.neurons_1)\n",
    "    layer_2      = fully_connected_layer(input_size=const.neurons_1, neurons=const.neurons_2)\n",
    "    layer_output = fully_connected_layer(input_size=const.neurons_2, neurons=const.number_classes)\n",
    "    \n",
    "    '''\n",
    "    print('W.shape = ', layer_1.weights.shape)\n",
    "    print('X', X.shape)\n",
    "    print(layer_1.weights.shape,  np.transpose(X).shape)\n",
    "    print(layer_1.biases.shape)\n",
    "    print(layer_output.weights.shape)\n",
    "    '''\n",
    "    ############################\n",
    "    a_1    = activation(tf.matmul(X, layer_1.weights) + layer_1.biases)\n",
    "    a_2    = activation(tf.matmul(a_1, layer_2.weights) + layer_2.biases)\n",
    "    logits = tf.matmul(a_2, layer_output.weights) + layer_output.biases\n",
    "    return logits\n",
    "\n",
    "def train(X_train, labels_train):\n",
    "    # Feeding the network\n",
    "    logits_ = feed_forward_neural_network(X_train) # computing the predictions\n",
    "    # Computing the cost\n",
    "    losses = tf.nn.softmax_cross_entropy_with_logits(labels=labels_train, logits=logits_)\n",
    "    cost = tf.reduce_mean(losses) \n",
    "    # Minimizing the cost\n",
    "    optmizer = tf.train.AdamOptimizer(learning_rate=const.learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(const.epochs):\n",
    "            epoch_loss = 0\n",
    "            for m in range(const.iterations):\n",
    "                batch_x, batch_y = mnist.train.next_batch(const.batch_size)\n",
    "                _, c = sess.run([optmizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "                epoch_loss += c\n",
    "            print('loss = ', epoch_loss)\n",
    "\n",
    "        # NOTE: تهبيدة\n",
    "        correct = tf.equal(tf.argmax(logits_, 1),\n",
    "                           tf.argmax(labels_train, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        # NOTE: تهبيدة\n",
    "        print('acc = ', accuracy.eval({x:mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "#train(mnist.train.images[0:10000], mnist.train.labels[0:10000])\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
